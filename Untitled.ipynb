{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import dlib\n",
    "import matplotlib.patches as patches\n",
    "from align import AlignDlib \n",
    "import matplotlib.pyplot as plt\n",
    "import model\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare database\n",
      "database\\Aaron_Eckhart_0001.jpg\n",
      "database\\Aaron_Guiel_0001.jpg\n",
      "database\\Aaron_Patterson_0001.jpg\n",
      "database\\Ashanti_0002.jpg\n",
      "database\\Ashraf_Ghani_0001.jpg\n",
      "database\\Astrid_Betancourt_0001.jpg\n",
      "database\\Audrey_Sauret_0001.jpg\n",
      "database\\Augustin_Calleri_0001.jpg\n",
      "database\\Avril_Lavigne_0001.jpg\n",
      "database\\Azra_Akin_0003.jpg\n",
      "database\\Nur Asiah.jpg\n",
      "Find vector for images in database\n"
     ]
    }
   ],
   "source": [
    "def check_dim(img):\n",
    "    if img.ndim == 3:\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "\n",
    "def align_image(img):\n",
    "    alignment = AlignDlib('models/landmarks.dat')\n",
    "    return alignment.align(96, img, alignment.getLargestFaceBoundingBox(img), \n",
    "                           landmarkIndices=AlignDlib.OUTER_EYES_AND_NOSE)\n",
    "\n",
    "def to_vector_embedded(img):\n",
    "    img = check_dim(img)\n",
    "    embedded = np.zeros((img.shape[0], 128))\n",
    "\n",
    "    for i, m in enumerate(img):\n",
    "        try:\n",
    "            images = align_image(m)\n",
    "            images = (images / 255.).astype(np.float32)\n",
    "        except:\n",
    "            images = cv2.resize(m,(96,96))\n",
    "        embedded[i] = nn4_small2_pretrained.predict(np.expand_dims(images, axis=0))[0]\n",
    "    return embedded\n",
    "\n",
    "def prepare_database():\n",
    "    label = []\n",
    "    foto = []\n",
    "    \n",
    "    for img in glob.glob('database/*.jpg'):\n",
    "        print(str(img))\n",
    "        label.append(str(img).split('\\\\')[1].split('.')[0])\n",
    "        image = cv2.imread(img)\n",
    "        image = cv2.resize(image, (250,250))\n",
    "        foto.append(np.array(image))\n",
    "    return np.array(foto), np.array(label)\n",
    "\n",
    "def webcam_face_detection():\n",
    "    video_capture = cv2.VideoCapture(0) # use for ipcamera \"http://192.168.43.1:8080/video\")\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        rects = detector(gray, 0)\n",
    "        print(rects)\n",
    "        for face in rects:\n",
    "            x = face.left()\n",
    "            y = face.top() \n",
    "            w = face.right() - face.left()\n",
    "            h = face.bottom() - face.top()\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 0)\n",
    "            face_region= frame[y:y+h, x:x+w]\n",
    "\n",
    "        cv2.imshow('Press \"q\" if your face has detected', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cv2.imwrite('only_face.jpg', face_region)\n",
    "            return face_region\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "def distance(emb1, emb2):\n",
    "    return np.sum(np.square(emb1 - emb2))\n",
    "\n",
    "def nearest_distance(new_face):\n",
    "    dist = []\n",
    "    for i in range(foto.shape[0]):\n",
    "        dist.append(distance(new_face, embedded[i]))\n",
    "    \n",
    "    idx_min = np.array(dist).argmin()\n",
    "    show_pair(new_face, idx_min)\n",
    "\n",
    "    return idx_min, dist[idx_min] \n",
    "    \n",
    "def show_pair(idx1, idx2):\n",
    "    plt.figure(figsize=(8,3))\n",
    "    plt.suptitle('Most similar face with distance = {distance(idx1, embedded[idx2]):.2f} \\n Not you?')\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(face_region)\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(align_image(foto[idx2]))\n",
    "    plt.xlabel(label[idx2])\n",
    "    plt.show()\n",
    "\n",
    "nn4_small2_pretrained = model.create_model()\n",
    "nn4_small2_pretrained.load_weights('models/nn4.small2.v1.h5')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    print('Prepare database')\n",
    "    foto, label = prepare_database()\n",
    "    print('Find vector for images in database')\n",
    "#     embedded = to_vector_embedded(foto)\n",
    "#     print('Start camera, please enter \"q\" if system has detected the face')\n",
    "#     face_region = webcam_face_detection()\n",
    "#     print('Start predicting...')\n",
    "#     new_face = to_vector_embedded(face_region)\n",
    "#     match, dist = nearest_distance(new_face)\n",
    "#     print('new face match to ' + label[match] + ' with distance = ' + str(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-6-7a8b8d8275ac>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-7a8b8d8275ac>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    count = 1\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(35,20))\n",
    "    count = 1\n",
    "    for i in range(11):\n",
    "        fig.add_subplot(2,6,count)\n",
    "        plt.imshow(align_image(foto[i]), cmap=None)\n",
    "        plt.xlabel(label[i], fontsize=25)\n",
    "        count += \n",
    "        plt.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
